# Ataques con IA Generativa

La Inteligencia Artificial Generativa ha abierto la puerta a la creación de contenido sintético altamente realista (audio, imágenes, video, texto), lo cual, si bien tiene muchas aplicaciones positivas, también presenta nuevos vectores de ataque y riesgos de seguridad. Esta sección explora estos usos ofensivos y las herramientas relacionadas.

**Tipos de Contenido Generativo y sus Riesgos:**

*   **Audio (Deepfake Audio):** Creación de grabaciones de voz falsas que pueden usarse para suplantación de identidad, fraude (vishing), desinformación.
*   **Imágenes (Deepfake Images/Synthetic Images):** Generación de imágenes falsas para crear perfiles falsos, desinformación, manipulación de evidencia, etc.
*   **Video (Deepfakes):** Creación de videos falsos donde se suplanta la identidad de personas, utilizados para desinformación, extorsión, o daño a la reputación.
*   **Texto (Generación de Lenguaje Natural):** Creación de correos de phishing altamente convincentes, generación de noticias falsas, creación de reseñas fraudulentas, automatización de interacciones maliciosas en redes sociales.

**Técnicas de Ataque Comunes:**

*   **Prompt Injection en LLMs:** Manipular las entradas de un Modelo de Lenguaje Grande (LLM) para que ignore sus instrucciones originales o revele información sensible. Esto es un riesgo crítico para aplicaciones que integran LLMs.
*   **Generación de Contenido para Ingeniería Social:** Usar IA generativa para crear señuelos (cebos) más efectivos y personalizados.

**Consideraciones:**

*   La detección de contenido generado por IA es un campo de investigación activo, pero sigue siendo un desafío ("la carrera armamentista" entre generación y detección).
*   La facilidad de acceso a estas herramientas aumenta el potencial de abuso a gran escala.

Explora los subdirectorios para obtener información más específica sobre cada tipo de contenido.
