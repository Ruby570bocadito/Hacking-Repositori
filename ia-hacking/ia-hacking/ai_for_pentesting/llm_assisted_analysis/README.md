# Análisis de Salida de Nmap Asistido por LLM (Simulado)

Este script demuestra cómo un Modelo de Lenguaje Grande (LLM) podría ser utilizado para analizar la salida XML de Nmap, resumir los servicios encontrados, sugerir vulnerabilidades comunes y proponer siguientes pasos en una prueba de penetración.

**Importante:** Este script utiliza una **simulación de LLM**. En un escenario real, las funciones `simulated_llm_call` deberían ser reemplazadas por llamadas a una API de LLM real. La simulación actual se basa en una base de conocimiento predefinida para mostrar el concepto.

## Archivos

*   `nmap_llm_analyzer.py`: Script principal que lee un archivo XML de Nmap, lo analiza y genera un reporte. Los archivos de entrada y salida se gestionan ahora relativos al directorio del script.
*   `sample_nmap_input.xml`: Un archivo XML de ejemplo que contiene una salida de Nmap. **Puedes y debes reemplazar el contenido de este archivo con tu propia salida de Nmap (generada con `nmap -sV -oX <nombre_archivo.xml> <objetivo>`) para probar el script con diferentes escenarios.**
*   `reporte_nmap_analizado.txt`: Archivo de salida generado por el script, que contiene el análisis. Se guarda en el mismo directorio que el script.

## Simulación de LLM

La función `simulated_llm_call` y la estructura `SIMULATED_LLM_KNOWLEDGE_BASE` en el script emulan cómo un LLM podría responder. Contienen respuestas predefinidas para puertos comunes.

**Para usar un LLM real, necesitarías:**
1.  Modificar la función `simulated_llm_call` en `nmap_llm_analyzer.py`.
2.  Integrar la librería cliente de tu LLM preferido (ej. OpenAI, Anthropic, HuggingFace Transformers para modelos locales).
3.  Diseñar prompts efectivos. Ejemplos de plantillas de prompts que se usarían:
    *   **Resumen del Servicio:** "Eres un asistente experto en ciberseguridad. Dada la siguiente información de un puerto escaneado: Puerto ID: {port_id}, Nombre del Servicio: {service_name}, Producto: {service_product}, Versión: {service_version}. Resume brevemente este servicio, sus usos comunes y lista 5 vulnerabilidades potenciales asociadas con él."
    *   **Pasos de Pentesting:** "Para el servicio {service_name} versión {service_version} en el puerto {port_id}, sugiere 5-7 pasos concretos que un pentester debería realizar para evaluarlo."
    *   **Preguntas de Seguimiento:** "Genera 3 preguntas de seguimiento que un analista de seguridad podría hacer a un LLM para obtener información más detallada sobre cómo explotar o investigar más a fondo el servicio {service_name} versión {service_version}."

## Cómo Ejecutar

1.  **Prepara tu archivo de entrada XML de Nmap:**
    *   Ejecuta Nmap contra un objetivo y guarda la salida en formato XML: `nmap -sV -oX mi_escaneo.xml <objetivo>`
    *   Reemplaza el contenido de `sample_nmap_input.xml` (ubicado en `ia-hacking/ai_for_pentesting/llm_assisted_analysis/`) con el contenido de `mi_escaneo.xml`.
2.  **Asegúrate de tener Python instalado.** (No se requieren librerías externas más allá de las estándar de Python para este script específico).
3.  **Navega al directorio del script y ejecútalo:**
    `cd ia-hacking/ai_for_pentesting/llm_assisted_analysis/`
    `python nmap_llm_analyzer.py`

    Si el archivo `sample_nmap_input.xml` no existe o está vacío la primera vez, el script creará uno con un contenido mínimo para evitar un error y te pedirá que lo edites.

## Resultados Esperados

*   El script leerá el archivo `sample_nmap_input.xml`.
*   Imprimirá en la consola el reporte generado.
*   Generará un archivo `reporte_nmap_analizado.txt` en el mismo directorio (`ia-hacking/ai_for_pentesting/llm_assisted_analysis/`), conteniendo el análisis detallado con las sugerencias del LLM simulado y una copia del XML de entrada.

Este ejemplo ilustra el potencial de integrar LLMs en herramientas de pentesting para automatizar el análisis inicial y la generación de ideas. Recuerda que la supervisión experta es crucial.
